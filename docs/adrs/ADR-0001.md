---
layout: default
title: ADR-0001 -- Design of the LLM-Play Environment Submission and Testing System
mermaid: true
---

# ADR-0001: Design of the Environment Submission and Testing System

## Context
LLM-Play aims to be a collaborative platform for exploring the capabilities of large language models (LLMs) through reinforcement learning (RL) environments. To support community contributions and ensure consistent, reproducible testing, we need a robust system for submitting and testing RL environments.

The system should:
- Allow users to submit custom RL environments easily.
- Ensure secure execution of submitted environments.
- Provide transparent results and community feedback mechanisms.

## Decision
We will design a **submission and testing system** leveraging the existing **Supabase backend**, **Next.js frontend** architecture, and **Supabase Edge Functions** for handling submissions and task orchestration. The core components will include:

1. **Environment Submission UI:**
   - A submission form at `/submit`, allowing users to upload environment code, descriptions, metadata, and testing parameters.
   - Client and server-side validation to ensure security and data integrity.

2. **Supabase Database Schema:**
   - **Table:** `environments`
     ```sql
     CREATE TABLE environments (
       id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
       user_id uuid REFERENCES auth.users(id),
       name text NOT NULL,
       description text,
       file_url text NOT NULL,
       metadata jsonb,
       status text DEFAULT 'pending',
       created_at timestamp DEFAULT now()
     );
     ```
   - **Table:** `jobs` (for managing test executions)
     ```sql
     CREATE TABLE jobs (
       id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
       environment_id uuid REFERENCES environments(id),
       status text DEFAULT 'queued',
       result jsonb,
       created_at timestamp DEFAULT now(),
       updated_at timestamp
     );
     ```

3. **Supabase Storage:**
   - Submitted environment files will be stored in Supabase Storage, with file URLs saved in the `environments` table.

4. **Supabase Edge Functions for Submission Handling:**
   - Use **Supabase Edge Functions** to process environment submissions and queue jobs for testing.
   - Edge Functions will handle lightweight tasks like validation, status updates, and task dispatching to the testing service.

5. **Testing Service:**
   - A background worker (Node.js or Dockerized service) will:
     - Fetch queued jobs from the `jobs` table.
     - Execute submitted environments in isolated sandboxes.
     - Capture results and update the `jobs` table.

6. **Result Visualization:**
   - A dashboard at `/dashboard` displaying submitted environments, test statuses, and results.
   - Community feedback features (voting, comments) for each environment.

## System Architecture Diagram
<div class="mermaid">
graph TD
    A[User Submits RL Environment] --> B[Next\.js Frontend Submission Form]
    B --> C[Supabase Edge Function]
    C --> D{Validation &amp; Queueing}
    D -->|Valid Submission| E[Supabase Storage --Environment Files--]
    D -->|Queue Job| F[Jobs Table in Supabase]
    F --> G[Background Worker --Node\.js/Docker--]
    G --> H[Execute Environment Test]
    H --> I[Update Job Status in Supabase]
    I --> J[Next\.js Dashboard Displays Results]
    J --> K[Community Feedback --Voting, Comments--]
</div>


## Database Schema Relationship Diagram
<div class="mermaid">
erDiagram
    USERS ||--o{ ENVIRONMENTS : "submits"
    ENVIRONMENTS ||--o{ JOBS : "has"
    
    USERS {
      uuid id PK
      text email
    }
    
    ENVIRONMENTS {
      uuid id PK
      uuid user_id FK
      text name
      text description
      text file_url
      jsonb metadata
      text status
      timestamp created_at
    }
    
    JOBS {
      uuid id PK
      uuid environment_id FK
      text status
      jsonb result
      timestamp created_at
      timestamp updated_at
    }
</div>

## Business Value
- **Community Engagement:** Encourages contributions from researchers and developers by simplifying the submission process.
- **Transparency & Reproducibility:** Ensures that all submitted environments and their test results are openly available, fostering trust within the community.
- **Scalability:** The architecture supports future expansions, such as multi-agent RL environments and complex analytics.
- **Low-Latency Processing:** Using Supabase Edge Functions reduces latency and enhances responsiveness for a global user base.

## Consequences
**Positive:**
- Streamlined submission and testing process will lower the barrier for community participation.
- Secure execution of code reduces risks of malicious submissions.
- Edge Functions simplify deployment and maintenance by integrating with the existing Supabase backend.

**Challenges:**
- Requires ongoing maintenance to manage the testing queue and ensure security in sandboxed environments.
- Edge Functions may have limitations for handling resource-heavy or long-running tasks, necessitating a hybrid architecture with external worker services.

## Alternatives Considered
1. **Manual Review and Testing:**
   - **Rejected** because it limits scalability and places a heavy burden on maintainers.

2. **Third-Party Platforms for Testing (e.g., AWS Lambda):**
   - **Rejected** due to increased complexity and costs associated with integrating external platforms.

3. **Using Only Node.js Background Workers:**
   - **Rejected** in favor of using Supabase Edge Functions for submission handling due to their seamless integration, low-latency, and open-source alignment.

## Effort Estimation
- **Time:** 4-6 person-weeks for initial implementation.
- **Resources:** 1 frontend developer, 1 backend developer, and 1 DevOps engineer.
- **Complexity:** Medium - requires secure sandboxing and integration with Supabase Edge Functions.
- **Dependencies:**
  - Supabase for authentication, storage, database management, and Edge Functions.
  - Docker for secure code execution.
- **Risks:**
  - Potential for security vulnerabilities in executing user-submitted code.
  - Scalability challenges if Edge Functions are pushed beyond their execution limits.

## Status
**Accepted** - This decision aligns with our goals of fostering community engagement, ensuring transparent, reproducible LLM benchmarking, and leveraging Supabase Edge Functions for efficient submission handling.